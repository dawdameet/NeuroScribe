model:
  name: "EnhancedClassifier"
  type: "Sequential"
  layers:
    - type: "Linear"
      input_size: 784
      output_size: 256
      activation: "LeakyReLU"
    - type: "BatchNorm"
      size: 256
    - type: "Dropout"
      p: 0.3
    - type: "Linear"
      input_size: 256
      output_size: 128
      activation: "LeakyReLU"
    - type: "BatchNorm"
      size: 128
    - type: "Dropout"
      p: 0.2
    - type: "Linear"
      input_size: 128
      output_size: 10  # No Softmax
  optimizer:
    type: "AdamW"  # Adam with Weight Decay
    learning_rate: 0.0005
    weight_decay: 0.01  # Regularization
  loss: "CrossEntropyLoss"
  metrics: ["accuracy"]

training:
  dataset: "MNIST"  # Choose between MNIST, CIFAR10, etc.
  epochs: 50
  batch_size: 128
  validation_split: 0.2
  early_stopping: True
  patience: 5  # Stop if validation loss doesn't improve for 5 epochs
  save_model: True
  model_path: "enhanced_model.pth"
  gradient_clipping: 5.0  # Prevents exploding gradients
  reduce_lr_on_plateau: True  # Reduces learning rate if no improvement
  lr_patience: 2  # Reduce LR if no improvement for 2 epochs
